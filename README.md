# ðŸ‡®ðŸ‡© IndoBERT Sentiment Analysis (Version 1)

Fine-tuning **IndoBERT** (`indobenchmark/indobert-base-p1`) for **Indonesian sentiment classification** using tweet data.

This repository contains two Google Colabâ€“ready notebooks:

| Notebook | Purpose |
|-----------|----------|
| [`notebooks/IndoBERT_V1.ipynb`](notebooks/IndoBERT_V1.ipynb) | End-to-end pipeline â€” from preprocessing and label encoding to fine-tuning, evaluation, and artifact export. |
| [`notebooks/IndoBERT_Inference_V1.ipynb`](notebooks/IndoBERT_Inference_V1.ipynb) | Inference-only notebook â€” load trained model, predict new texts, or run batch CSV predictions. |

---

## ðŸ§­ Project Overview

**Objective:**  
Train a robust IndoBERT model to classify Indonesian texts (e.g., tweets) into `positif`, `netral`, or `negatif` sentiments.

**Workflow Summary**
1. **Preprocessing** â€“ load raw CSV (`tweet.csv`), clean whitespace, encode sentiment labels.  
2. **Dataset Split** â€“ 80 / 10 / 10 stratified split for train, validation, and test.  
3. **Tokenization** â€“ IndoBERT tokenizer with `max_length=128`.  
4. **Fine-Tuning** â€“ Transformers `Trainer`, optimizing for **macro-F1**.  
5. **Evaluation** â€“ accuracy, precision, recall, macro-F1, confusion matrix.  
6. **Export** â€“ best model checkpoint, tokenizer, label maps, metrics, and reports.  
7. **Inference** â€“ predict single texts or whole CSV files.

---

## ðŸ“‚ Folder Structure

```
Sentiment_IndoBERT/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ IndoBERT_V1.ipynb               # Full fine-tuning & evaluation
â”‚   â””â”€â”€ IndoBERT_Inference_V1.ipynb     # Inference-only version
â”‚
â”œâ”€â”€ outputs/                            # (optional) commit selected small files only
â”‚   â”œâ”€â”€ label_maps.json
â”‚   â”œâ”€â”€ classification_report.txt
â”‚   â”œâ”€â”€ test_metrics.json
â”‚   â”œâ”€â”€ confusion_matrix_test.png
â”‚   â””â”€â”€ best_model/                     # (large) model weights + tokenizer â€” usually not committed
â”‚
â”œâ”€â”€ data/                               # (optional) dataset folder
â”‚   â””â”€â”€ tweet.csv
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore
```

> **Note:** The notebooks save artifacts to your Google Drive at  
> `/content/drive/MyDrive/Proyek/Sentiment_IndoBERT/`

---

## âš™ï¸ Paths (Colab Defaults)

| Variable | Path |
|-----------|------|
| **DATA_PATH** | `/content/drive/MyDrive/Proyek/Sentiment_IndoBERT/Data/tweet.csv` |
| **OUTPUT_DIR** | `/content/drive/MyDrive/Proyek/Sentiment_IndoBERT` |
| **MODEL_DIR (for inference)** | `/content/drive/MyDrive/Proyek/Sentiment_IndoBERT/best_model` |

> Ensure your `tweet.csv` has columns:  
> `tweet` â†’ text input, and `sentimen` â†’ label (`positif`, `netral`, `negatif`).

---

## ðŸš€ How to Run (Training)

1. Open **[`notebooks/IndoBERT_V1.ipynb`](notebooks/IndoBERT_V1.ipynb)** in **Google Colab**.
2. Run **Process 1** (Clean Install). If prompted, **restart runtime** after installs.
3. Run **Process 2â€“9** in order (mount Drive, config, load/encode, split, tokenize, train, evaluate, export).
4. Review the outputs in Drive:
   - `/best_model/` (model + tokenizer)
   - `label_maps.json`, `test_metrics.json`, `classification_report.txt`
   - `confusion_matrix_test.png`

**Example classification report** (illustrative):

```
              precision    recall  f1-score   support
    negatif      0.613     0.706     0.656       119
     netral      0.640     0.603     0.621       121
    positif      0.625     0.569     0.596       123
   macro avg    0.626     0.626     0.624       363
   accuracy                          0.625       363
```

---

## ðŸ” How to Run (Inference Only)

1. Open **[`notebooks/IndoBERT_Inference_V1.ipynb`](notebooks/IndoBERT_Inference_V1.ipynb)**.
2. Confirm your model exists at: `/content/drive/MyDrive/Proyek/Sentiment_IndoBERT/best_model`.
3. Run **Process 1â€“3** to install dependencies, mount Drive, and load model.
4. Predict directly in Python:

```python
predict_texts([
    "Pelayanannya sangat memuaskan, terima kasih!",
    "Biasa saja sih, tidak terlalu istimewa.",
    "Sangat buruk, saya kecewa."
])
# -> ['positif', 'netral', 'negatif']
```

5. Predict from a CSV:

```python
CSV_PATH = "/content/drive/MyDrive/Proyek/Sentiment_IndoBERT/Data/tweet.csv"
TEXT_COL = "tweet"
```
Outputs a file like `predictions_YYYYMMDD_HHMMSS.csv` to your Drive project folder.

---

## ðŸ§  Model & Training Configuration

| Parameter | Value |
|------------|--------|
| Model | `indobenchmark/indobert-base-p1` |
| Tokenizer | IndoBERT FastTokenizer |
| Epochs | 3 |
| Batch Size | 16 |
| Max Length | 128 |
| Learning Rate | 2e-5 |
| Optimizer | AdamW |
| Evaluation Metric | **Macro-F1** |
| Mixed Precision | FP16 / BF16 (auto-select) |

---

## ðŸ“Š Outputs and Artifacts

- **best_model/** â€“ Saved weights + tokenizer  
- **label_maps.json** â€“ `label2id` & `id2label` mappings  
- **classification_report.txt** â€“ per-class Precision / Recall / F1  
- **test_metrics.json** â€“ overall metrics summary  
- **confusion_matrix_test.png** â€“ visual evaluation  
- **predictions_*.csv** â€“ batch inference results  

---

## ðŸ’¡ Tips & Troubleshooting

- **Dependency conflicts in Colab**: The training notebook includes a robust **Process 1** that removes RAPIDS/dask/gcsfs, pins `pyarrow==19.0.0`, installs NLP libs, and runs `pip check`.
- **Longer texts**: Increase `MAX_LEN` to `192` (slower but may improve recall).
- **More training**: Raise `EPOCHS` to 4â€“5 (monitor validation macro-F1).
- **GPU**: Use T4/A100 on Colab for faster training.
- **Large files**: Donâ€™t commit `best_model/` to GitHub; use `.gitignore`.

---

## ðŸ§¾ Citation

If you use this project, please cite:

```
@misc{Sentiment_IndoBERT_2025,
  author = {moonandart (Aris)},
  title  = {IndoBERT Sentiment Analysis},
  year   = {2025},
  url    = {https://github.com/moonandart/Sentiment_IndoBERT}
}
```

---

## ðŸ§© Dependencies

See [`requirements.txt`](requirements.txt). For Colab, the training notebookâ€™s **Process 1** installs:
- `transformers`, `datasets<3.0.0`, `accelerate`
- `scikit-learn`, `matplotlib`, `sentencepiece`
- `pyarrow==19.0.0` (pinned)
- `jedi` (for IPython completeness)

---

## ðŸ Author

**Aris (moonandart)**  
AI & NLP enthusiast â€” exploring sentiment analysis, BERT fine-tuning, and contextual AI tools.  
ðŸ”— https://github.com/moonandart

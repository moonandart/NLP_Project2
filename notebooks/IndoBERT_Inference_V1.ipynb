{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07f9e605",
   "metadata": {},
   "source": [
    "\n",
    "# IndoBERT Sentiment — Inference-Only Notebook (V1)\n",
    "\n",
    "## Process Overview\n",
    "1) **Install Dependencies** — Make sure required libraries are available.\n",
    "2) **Mount Google Drive & Set Paths** — Use the trained model at `/content/drive/MyDrive/Proyek/Sentiment_IndoBERT/best_model`.\n",
    "3) **Load Model & Label Maps** — Load tokenizer/model from the saved directory, get `id2label` mapping.\n",
    "4) **Define Batch Inference Helper** — `predict_texts()` for fast batched predictions.\n",
    "5) **(Optional) CSV Batch Prediction** — Read a CSV with a text column, write predictions to a new CSV.\n",
    "6) **Quick Demo** — Run a few example sentences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24442045",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Process 1: Install Dependencies ===\n",
    "!pip install -q --upgrade transformers datasets accelerate scikit-learn sentencepiece\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d111cab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Process 2: Mount Google Drive & Set Paths ===\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "from pathlib import Path\n",
    "MODEL_DIR = Path(\"/content/drive/MyDrive/Proyek/Sentiment_IndoBERT/best_model\")\n",
    "OUTPUT_DIR = Path(\"/content/drive/MyDrive/Proyek/Sentiment_IndoBERT\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"MODEL_DIR:\", MODEL_DIR)\n",
    "print(\"OUTPUT_DIR:\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b0c8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Process 3: Load Model & Label Maps ===\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR.as_posix())\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR.as_posix())\n",
    "model.eval()\n",
    "\n",
    "label_maps_path = OUTPUT_DIR / \"label_maps.json\"\n",
    "if label_maps_path.exists():\n",
    "    with open(label_maps_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        maps = json.load(f)\n",
    "        id2label = {int(k): v for k, v in maps.get(\"id2label\", {}).items()}\n",
    "else:\n",
    "    id2label = getattr(model.config, \"id2label\", None)\n",
    "    if isinstance(id2label, dict):\n",
    "        id2label = {int(k): v for k, v in id2label.items()}\n",
    "    else:\n",
    "        id2label = {i: str(i) for i in range(model.config.num_labels)}\n",
    "print(\"id2label:\", id2label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855f75bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Process 4: Define Batch Inference Helper ===\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "MAX_LEN = 128\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "def predict_texts(texts, batch_size=64):\n",
    "    ds = Dataset.from_dict({\"text\": list(texts)}).map(\n",
    "        lambda b: tokenizer(b[\"text\"], truncation=True, max_length=MAX_LEN, padding=False),\n",
    "        batched=True\n",
    "    )\n",
    "    ds.set_format(type=\"torch\")\n",
    "    loader = DataLoader(ds, batch_size=batch_size, collate_fn=data_collator)\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = {k: v.to(model.device) for k, v in batch.items()}\n",
    "            logits = model(**batch).logits\n",
    "            batch_preds = torch.argmax(logits, dim=-1).cpu().tolist()\n",
    "            preds.extend(batch_preds)\n",
    "    return [id2label[int(i)] for i in preds]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6672b357",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Process 5 (Optional): CSV Batch Prediction ===\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "CSV_PATH = \"/content/drive/MyDrive/Proyek/Sentiment_IndoBERT/Data/tweet.csv\"\n",
    "TEXT_COL = \"tweet\"\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "if TEXT_COL not in df.columns:\n",
    "    raise ValueError(f\"Column '{TEXT_COL}' not found in {CSV_PATH}. Available: {list(df.columns)}\")\n",
    "\n",
    "texts = df[TEXT_COL].astype(str).fillna(\"\").tolist()\n",
    "preds = predict_texts(texts, batch_size=128)\n",
    "\n",
    "out_name = f\"predictions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "out_path = (OUTPUT_DIR / out_name).as_posix()\n",
    "\n",
    "df_out = df.copy()\n",
    "df_out[\"prediction\"] = preds\n",
    "df_out.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Saved predictions to:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8e0d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Process 6: Quick Demo ===\n",
    "predict_texts([\n",
    "    \"Pelayanannya sangat memuaskan, terima kasih!\",\n",
    "    \"Biasa saja sih, tidak terlalu istimewa.\",\n",
    "    \"Sangat buruk, saya kecewa.\"\n",
    "])\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
